#!/usr/bin/python3
#coded by 0xbit

import re, os, ua_generator, asyncio, aiohttp

RESET = "\033[0m"
GREEN = "\033[92m"
RED = "\033[91m"
green_dot = '[\033[92m●\033[0m]'
green_command = '[\033[92m+\033[0m]'
green_question = '[\033[92m?\033[0m]'
red_dot = '[\033[91m●\033[0m]'

def banner():
    os.system('clear')
    banner = f'''

                |░░░░░░░░░░░░░░░░░
                |░░░▄░▀▄░░░▄▀░▄░░░
                |░░░█▄███████▄█░░░
                |░░░███▄███▄███░░░
                |░░░▀█████████▀░░░
                |░░░░▄▀░░░░░▀▄░░░░
                |░░░░░░░░░░░░░░░░░
                |
                |
                |
                {GREEN}DEDSEC FAST PROXY SCRAPER{RESET}
                By: 0xbit
    '''
    print(banner)
    
proxy_urls = [
    'https://api.proxyscrape.com/v2/?request=displayproxies',
    'https://raw.githubusercontent.com/officialputuid/KangProxy/KangProxy/http/http.txt',
    'https://raw.githubusercontent.com/roosterkid/openproxylist/main/HTTPS_RAW.txt',
    'https://raw.githubusercontent.com/yuceltoluyag/GoodProxy/main/raw.txt',
    'https://raw.githubusercontent.com/ShiftyTR/Proxy-List/master/http.txt',
    'https://raw.githubusercontent.com/ShiftyTR/Proxy-List/master/https.txt',
    'https://raw.githubusercontent.com/mmpx12/proxy-list/master/https.txt',
    'https://raw.githubusercontent.com/TheSpeedX/PROXY-List/master/http.txt',
    'https://raw.githubusercontent.com/jetkai/proxy-list/main/online-proxies/txt/proxies.txt',
    'https://raw.githubusercontent.com/hookzof/socks5_list/master/proxy.txt',
    'https://raw.githubusercontent.com/clarketm/proxy-list/master/proxy-list-raw.txt',
    'https://raw.githubusercontent.com/sunny9577/proxy-scraper/master/proxies.txt',
    'https://raw.githubusercontent.com/opsxcq/proxy-list/master/list.txt',
    'https://proxyspace.pro/http.txt',
    'https://api.proxyscrape.com/?request=displayproxies&proxytype=http',
    'https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/http.txt',
    'http://worm.rip/http.txt',
    'http://alexa.lr2b.com/proxylist.txt',
    'https://api.openproxylist.xyz/http.txt',
    'http://rootjazz.com/proxies/proxies.txt',
    'https://proxy-spider.com/api/proxies.example.txt',
    'https://api.proxyscrape.com/v2/?request=getproxies&protocol=http&timeout=10000&country=all&ssl=all&anonymity=all',
    'https://www.proxydocker.com/en/proxylist/download?email=noshare&country=all&city=all&port=all&type=all&anonymity=all&state=all&need=all',
    'https://api.proxyscrape.com/v2/?request=getproxies&protocol=http&timeout=10000&country=all&ssl=all&anonymity=anonymous',
    'https://raw.githubusercontent.com/sunny9577/proxy-scraper/master/generated/http_proxies.txt',
    'https://raw.githubusercontent.com/sunny9577/proxy-scraper/master/proxies.txt',
    'https://raw.githubusercontent.com/Firdoxx/proxy-list/main/https',
    'https://raw.githubusercontent.com/Firdoxx/proxy-list/main/http',
    'https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/http.txt',
    'https://raw.githubusercontent.com/mmpx12/proxy-list/master/http.txt',
    'https://raw.githubusercontent.com/mmpx12/proxy-list/master/https.txt',
    'https://raw.githubusercontent.com/Zaeem20/FREE_PROXIES_LIST/master/https.txt',
    'https://raw.githubusercontent.com/zevtyardt/proxy-list/main/http.txt',
    'https://raw.githubusercontent.com/prxchk/proxy-list/main/http.txt',
    'https://raw.githubusercontent.com/Zaeem20/FREE_PROXIES_LIST/master/http.txt',
    'https://raw.githubusercontent.com/ALIILAPRO/Proxy/main/http.txt',
    'https://raw.githubusercontent.com/casals-ar/proxy-list/main/http',
    'https://raw.githubusercontent.com/casals-ar/proxy-list/main/https',
    'https://raw.githubusercontent.com/MuRongPIG/Proxy-Master/main/http.txt',
    'https://raw.githubusercontent.com/vakhov/fresh-proxy-list/master/http.txt',
    'https://raw.githubusercontent.com/vakhov/fresh-proxy-list/master/https.txt',
    'https://raw.githubusercontent.com/Jakee8718/Free-Proxies/main/proxy/-http%20and%20https.txt',
    'https://raw.githubusercontent.com/Tsprnay/Proxy-lists/master/proxies/http.txt',
    'https://raw.githubusercontent.com/Tsprnay/Proxy-lists/master/proxies/https.txt',
    'https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/socks5.txt',
    'https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/socks4.txt',
    'https://api.proxyscrape.com/v2/?request=getproxies&protocol=socks5&timeout=10000&country=all',
    'https://www.proxy-list.download/api/v1/get?type=socks5',
    'https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/socks5.txt',
    'https://raw.githubusercontent.com/hookzof/socks5_list/master/proxy.txt',
    'https://raw.githubusercontent.com/jetkai/proxy-list/main/online-proxies/txt/proxies.txt',
    'https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/socks5.txt',
    'https://raw.githubusercontent.com/roosterkid/openproxylist/main/SOCKS5_RAW.txt',
    'https://raw.githubusercontent.com/prxchk/proxy-list/main/socks5.txt',
    'https://raw.githubusercontent.com/a2u/free-proxy-list/master/free-proxy-list.txt',
    'https://raw.githubusercontent.com/mishakorzik/Free-Proxy/main/proxy.txt',
    'https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/http.txt',
    'https://slims-sf.com/Htewarukofdcn/proxy.txt',
    'https://api.proxyscrape.com/v2/?request=displayproxies',
    'https://raw.githubusercontent.com/officialputuid/KangProxy/KangProxy/http/http.txt',
    'https://raw.githubusercontent.com/roosterkid/openproxylist/main/HTTPS_RAW.txt',
    'https://raw.githubusercontent.com/yuceltoluyag/GoodProxy/main/raw.txt',
    'https://slims-sf.com/Htewarukofdcn/https.txt',
    'https://slims-sf.com/Htewarukofdcn/http.txt'
]

proxy_pattern = re.compile(r"^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d+$")

async def fetch_proxies(session, url):
    headers = {"User-Agent": str(ua_generator.generate())}
    try:
        async with session.get(url, headers=headers, timeout=20) as response:
            if response.status == 200:
                text = await response.text()
                proxies = text.splitlines()
                return proxies
            else:
                print(f"\t {red_dot} Failed to fetch: {RED}{url}{RESET} - HTTP {RED}{response.status}{RESET}")
    except Exception as e:
        print(f"\t {red_dot} Error fetching: {RED}{url}{RESET}: {RED}{e}{RESET}")
    return []

async def scrape_proxies():
    proxies = set()
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_proxies(session, url) for url in proxy_urls]
        results = await asyncio.gather(*tasks)

        for url, result in zip(proxy_urls, results):
            if result:
                valid_proxies = {proxy.strip() for proxy in result if proxy_pattern.match(proxy)}
                print(f"\t {green_command} Extracted {len(valid_proxies)} valid proxies from [{GREEN}{url}{RESET}]")
                proxies.update(valid_proxies)

    print(f"\n\t {green_dot} Total Unique Proxies Collected: [{GREEN}{len(proxies):,}{RESET}]\n")

    with open("proxies.txt", "w") as f:
        f.write("\n".join(proxies))

    print(f"\t {green_dot} Proxies saved to proxies.txt!\n")

if __name__ == "__main__":
    banner()
    try:
        input(f'\n\t {green_question} Press Enter to start scraping proxies...')
        print(f"\n\t {green_dot} Scraping proxies...\n")
        asyncio.run(scrape_proxies())
    except KeyboardInterrupt:
        print(f"\n\n\t {red_dot} Scraping canceled by user.\n")
    except Exception as e:
        print(f"\n\t {red_dot} An error occurred: {RED}{e}{RESET}\n")
